{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate `bicorr` from `cced`\n",
    "\n",
    "Author: Patricia Schuster  \n",
    "Date: Fall 2016/Winter 2017  \n",
    "Institution: University of Michigan NERS  \n",
    "Email: pfschus@umich.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we doing today?\n",
    "Goal: Write the script to produce the bicorrelation plot. Here are the major steps in this work:\n",
    "\n",
    "1. Read in `cced` files from subfolders (each a different measurement from the same measurement set)\n",
    "2. Parse the data\n",
    "3. Store information about detector pair correlations\n",
    "4. Identify indices of the verified detector and corresponding fission chamber channels\n",
    "5. Store timing info, detector pair, correlation type\n",
    "6. Write info out to file\n",
    "7. Read and write into multiple subfolders\n",
    "8. Read into another script\n",
    "9. Produce bicorrelation plot\n",
    "\n",
    "Note: I found a better way to do the data read-in, which I explore in `bicorr_readin.ipynb`.\n",
    "\n",
    "I need to parse the `cced` file for each measurement set to produce a distribution of counts vs. $\\Delta t_A$ vs. $\\Delta t_B$ for two pairs of detectors. \n",
    "\n",
    "Select two detectors in the array: A and B. Find events where there are triggers in the fission chamber, A, and B. Calculate the time of the interaction in A and B relative to the fission chamber as:\n",
    "\n",
    "$$\\Delta t_A = t_A - t_{FC}$$\n",
    "$$\\Delta t_B = t_B - t_{FC}$$\n",
    "\n",
    "The money plot looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"fig/plot_sketch.png\",width=80%,height=80%>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"fig/plot_sketch.png\",width=80%,height=80%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os.path\n",
    "import time\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan) # print entire matrices\n",
    "import sys\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to construct a new script called `bicorr.py`, so set up some code to import and refresh `bicorr.py` for when the time comes. I keep `bicorr.py` in a separate folder called `scripts` where I version control everything. \n",
    "\n",
    "First I need to add the folder that contains `bicorr.py` to my system path for this current python session. I wrote a tutorial with more detailed instructions on how to do this here: <https://github.com/pfschus/python-tutorial-file-manipulation/blob/master/python_access_other_folders.ipynb>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../scripts/')\n",
    "import bicorr as bicorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I make modifications to my `bicorr.py` scripts while running this Jupyter notebook and I want to refresh all the functions, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Read in cced files from subfolders\n",
    "\n",
    "## Download part of the `cced1` file to my local machine\n",
    "\n",
    "I need to download part of the `cced1` file.\n",
    "\n",
    "To copy part of the `cced1` file into another file, run the following command:\n",
    "\n",
    "`head -n 1000 cced1 > cced1_part`\n",
    "\n",
    "This copies the first 1000 lines to a new file called `cced1_part`. I'm going to do that, but for 10,000 lines so I have a smaller file to work with while I write the `bicorr` script.\n",
    "\n",
    "The contents of the `cced` file looks like:\n",
    "\n",
    "```\n",
    "1    7 2 60.43050003051757812500    1.65172    0.20165\n",
    "1    40 1 -237.56460189819335937500    0.36266    0.03698\n",
    "2    0 2 56.02870178222656250000    1.00000    0.37657\n",
    "2    32 2 55.86729812622070312500    1.00000    0.38003\n",
    "2    33 2 76.49300003051757812500    0.17479    0.03698\n",
    "3    24 2 58.41870117187500000000    0.90767    0.12300\n",
    "3    31 2 68.34080123901367187500    0.25033    0.04415\n",
    "4    10 1 60.55670166015625000000    6.73639    0.82892\n",
    "4    15 2 69.21060180664062500000    3.84989    0.48209\n",
    "5    1 1 58.71749877929687500000    1.83345    0.16218\n",
    "5    12 2 -7.76129913330078125000    0.25288    0.03376\n",
    "6    4 2 57.22999954223632812500    0.44034    0.05057\n",
    "6    6 2 10.50279998779296875000    0.27631    0.03217\n",
    "7    32 2 55.97380065917968750000    1.00000    0.47541\n",
    "7    44 2 67.53409957885742187500    0.42906    0.06017\n",
    "8    17 2 56.86849975585937500000    0.08842    0.03812\n",
    "8    27 2 55.96139907836914062500    1.63040    0.19290\n",
    "8    30 2 106.28549957275390625000    3.32284    0.41720\n",
    "9    41 2 56.37910079956054687500    0.28385    0.04117\n",
    "9    42 1 57.03319931030273437500    1.57115    0.22264\n",
    "10    22 2 58.14680099487304687500    0.84705    0.13257\n",
    "10    28 2 325.81359863281250000000    0.42242    0.06293\n",
    "11    0 2 52.17919921875000000000    1.00000    0.34562\n",
    "11    14 1 64.22990036010742187500    0.25867    0.04041\n",
    "12    16 2 56.74929809570312500000    1.00000    0.44734\n",
    "12    24 1 128.21559906005859375000    1.11157    0.13403\n",
    "13    37 2 59.00970077514648437500    1.79579    0.24159\n",
    "13    47 2 58.27090072631835937500    0.86533    0.09690\n",
    "14    32 2 55.12779998779296875000    1.00000    0.38950\n",
    "14    46 2 64.88420104980468750000    1.73512    0.20411\n",
    "```\n",
    "Where the columns are:\n",
    "\n",
    "* 1) event number: `evnum`\n",
    "* 2) channel number `chnum`\n",
    "* 3) particle (1=n, 2=g) `part`\n",
    "* 4) time, $ns$ `time`\n",
    "* 5) PSD total integral `totint`\n",
    "* 6) pulse height `height`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the `cced` file\n",
    "Use a simple `open` command, and tell Python to open it read only with option `r`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanFile = open('../datar/cced1_part','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='../datar/cced1_part' mode='r' encoding='cp1252'>\n"
     ]
    }
   ],
   "source": [
    "print(cleanFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access `cced` files in subfolders\n",
    "When I do the analysis on the cluster, I will have to get data out of subfolders separated by measurement. How do I do that? I created a new folder `1` on my local machine with `cced1_part` in it, but then I renamed it to `cced1` to match the filenames that I will encounter on the cluster. Try accessing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='../datar/1/cced1' mode='r' encoding='cp1252'>\n"
     ]
    }
   ],
   "source": [
    "cleanFile = open(\"../datar/1/cced1\",'r')\n",
    "print(cleanFile)\n",
    "cleanFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access `cced` files in other locations\n",
    "\n",
    "In addition to being in numbered subfolders, I may want to run the analysis from a different directory completely. How can I specify a different `root_path` using a relative folder location?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = '../datar'\n",
    "folder = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datar1'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(root_path + '/' + str(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cced1']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(root_path + '/' + str(folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a default `root_path == None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = None\n",
    "if root_path == None: root_path = os.getcwd()\n",
    "folder = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pfschus\\\\Box Sync\\\\Projects\\\\fnpc\\\\methods/1'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(root_path + '/' + str(folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from the `cced` file: Attempt 1, `for line in cleanFile:`\n",
    "\n",
    "Use the method that Matthew used in his script `crossCorr_v4.py` which also parses the `cced` file. Read in the `cced` file and look at its contents. \n",
    "\n",
    "This strategy uses an iterator to go line-by-line. The trouble here is that you can't go back in time to previous lines, so I will have to store the event information from every line even if I don't know whether that event is a bicorrelation event. Also, there is no way to tell the iterator to only parse a few lines, or a set range of lines. It will always parse the entire file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cced1_part']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../datar/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '7', '2', '60.43050003051757812500', '1.65172', '0.20165']\n",
      "['1', '40', '1', '-237.56460189819335937500', '0.36266', '0.03698']\n",
      "['2', '0', '2', '56.02870178222656250000', '1.00000', '0.37657']\n",
      "['2', '32', '2', '55.86729812622070312500', '1.00000', '0.38003']\n",
      "['2', '33', '2', '76.49300003051757812500', '0.17479', '0.03698']\n",
      "['3', '24', '2', '58.41870117187500000000', '0.90767', '0.12300']\n",
      "['3', '31', '2', '68.34080123901367187500', '0.25033', '0.04415']\n",
      "['4', '10', '1', '60.55670166015625000000', '6.73639', '0.82892']\n",
      "['4', '15', '2', '69.21060180664062500000', '3.84989', '0.48209']\n",
      "['5', '1', '1', '58.71749877929687500000', '1.83345', '0.16218']\n",
      "['5', '12', '2', '-7.76129913330078125000', '0.25288', '0.03376']\n",
      "['6', '4', '2', '57.22999954223632812500', '0.44034', '0.05057']\n",
      "['6', '6', '2', '10.50279998779296875000', '0.27631', '0.03217']\n",
      "['7', '32', '2', '55.97380065917968750000', '1.00000', '0.47541']\n",
      "['7', '44', '2', '67.53409957885742187500', '0.42906', '0.06017']\n",
      "['8', '17', '2', '56.86849975585937500000', '0.08842', '0.03812']\n",
      "['8', '27', '2', '55.96139907836914062500', '1.63040', '0.19290']\n",
      "['8', '30', '2', '106.28549957275390625000', '3.32284', '0.41720']\n",
      "['9', '41', '2', '56.37910079956054687500', '0.28385', '0.04117']\n",
      "['9', '42', '1', '57.03319931030273437500', '1.57115', '0.22264']\n",
      "['10', '22', '2', '58.14680099487304687500', '0.84705', '0.13257']\n",
      "['10', '28', '2', '325.81359863281250000000', '0.42242', '0.06293']\n",
      "['11', '0', '2', '52.17919921875000000000', '1.00000', '0.34562']\n",
      "['11', '14', '1', '64.22990036010742187500', '0.25867', '0.04041']\n",
      "['12', '16', '2', '56.74929809570312500000', '1.00000', '0.44734']\n",
      "['12', '24', '1', '128.21559906005859375000', '1.11157', '0.13403']\n",
      "['13', '37', '2', '59.00970077514648437500', '1.79579', '0.24159']\n",
      "['13', '47', '2', '58.27090072631835937500', '0.86533', '0.09690']\n",
      "['14', '32', '2', '55.12779998779296875000', '1.00000', '0.38950']\n",
      "['14', '46', '2', '64.88420104980468750000', '1.73512', '0.20411']\n",
      "['15', '1', '1', '56.41749954223632812500', '0.50192', '0.03073']\n",
      "['15', '12', '2', '-26.90169906616210937500', '2.58153', '0.32763']\n",
      "['15', '13', '2', '-5.64950180053710937500', '0.36045', '0.05393']\n",
      "['16', '16', '2', '56.83219909667968750000', '1.00000', '0.43127']\n",
      "['16', '22', '2', '26.67750167846679687500', '0.89639', '0.13186']\n",
      "['16', '30', '2', '-75.39820098876953125000', '0.63213', '0.07415']\n",
      "['16', '32', '2', '57.01269912719726562500', '1.00000', '0.43167']\n",
      "['16', '43', '2', '79.02500152587890625000', '0.28174', '0.05237']\n",
      "['17', '37', '2', '56.50230026245117187500', '0.23646', '0.03199']\n",
      "['17', '38', '2', '52.18550109863281250000', '0.87098', '0.12513']\n",
      "['18', '4', '2', '57.79380035400390625000', '0.73533', '0.08189']\n",
      "['18', '9', '2', '229.43970108032226562500', '0.66478', '0.08946']\n",
      "['19', '5', '2', '57.93629837036132812500', '0.36509', '0.05088']\n",
      "['19', '7', '2', '53.36640167236328125000', '0.94655', '0.12489']\n"
     ]
    }
   ],
   "source": [
    "cleanFile = open(\"../datar/1/cced1\",'r')\n",
    "cleanFile.seek(0,0) # Go back to the beginning of the file (if you have been trying other things the current position may be later)\n",
    "\n",
    "# What does the file look like?\n",
    "for line in cleanFile:\n",
    "    holder = line.split()\n",
    "    if int(holder[0]) < 20: # Only look at first 20 events\n",
    "        print(holder)\n",
    "    \n",
    "cleanFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from the `cced` file: Attempt 2, `np.genfromtxt`\n",
    "\n",
    "Instead of reading the `cced` file line by line using an iterator, pull in matches of the `cced` file using the numpy function `np.genfromtxt`. Documentation is here: <https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html>\n",
    "\n",
    "This function offers the capability of specifying the `dtype`, which is the data type for each value along a row. Follow Matthew's method with `ccedType` in his script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 7, 2, 60.43050003051758, 1.6517200469970703, 0.2016499936580658)\n",
      " (1, 40, 1, -237.56460189819336, 0.3626599907875061, 0.036979999393224716)\n",
      " (2, 0, 2, 56.02870178222656, 1.0, 0.3765699863433838)\n",
      " (2, 32, 2, 55.8672981262207, 1.0, 0.3800300061702728)\n",
      " (2, 33, 2, 76.49300003051758, 0.17478999495506287, 0.036979999393224716)\n",
      " (3, 24, 2, 58.418701171875, 0.9076700210571289, 0.12300000339746475)\n",
      " (3, 31, 2, 68.34080123901367, 0.25033000111579895, 0.04414999857544899)\n",
      " (4, 10, 1, 60.55670166015625, 6.736390113830566, 0.8289200067520142)\n",
      " (4, 15, 2, 69.21060180664062, 3.8498899936676025, 0.4820899963378906)\n",
      " (5, 1, 1, 58.717498779296875, 1.8334499597549438, 0.16218000650405884)\n",
      " (5, 12, 2, -7.761299133300781, 0.2528800070285797, 0.03376000002026558)\n",
      " (6, 4, 2, 57.22999954223633, 0.4403400123119354, 0.05056999996304512)\n",
      " (6, 6, 2, 10.502799987792969, 0.276309996843338, 0.03217000141739845)\n",
      " (7, 32, 2, 55.97380065917969, 1.0, 0.47541001439094543)\n",
      " (7, 44, 2, 67.53409957885742, 0.4290600121021271, 0.060169998556375504)\n",
      " (8, 17, 2, 56.868499755859375, 0.08842000365257263, 0.038120001554489136)\n",
      " (8, 27, 2, 55.96139907836914, 1.6303999423980713, 0.19290000200271606)\n",
      " (8, 30, 2, 106.2854995727539, 3.3228399753570557, 0.4171999990940094)\n",
      " (9, 41, 2, 56.37910079956055, 0.2838500142097473, 0.04117000102996826)\n",
      " (9, 42, 1, 57.033199310302734, 1.5711499452590942, 0.2226399928331375)\n",
      " (10, 22, 2, 58.14680099487305, 0.8470500111579895, 0.13256999850273132)\n",
      " (10, 28, 2, 325.8135986328125, 0.4224199950695038, 0.06293000280857086)\n",
      " (11, 0, 2, 52.17919921875, 1.0, 0.3456200063228607)\n",
      " (11, 14, 1, 64.22990036010742, 0.25867000222206116, 0.04041000083088875)\n",
      " (12, 16, 2, 56.749298095703125, 1.0, 0.4473400115966797)\n",
      " (12, 24, 1, 128.2155990600586, 1.1115700006484985, 0.13402999937534332)\n",
      " (13, 37, 2, 59.009700775146484, 1.7957899570465088, 0.2415899932384491)\n",
      " (13, 47, 2, 58.27090072631836, 0.8653299808502197, 0.09690000116825104)\n",
      " (14, 32, 2, 55.12779998779297, 1.0, 0.3894999921321869)\n",
      " (14, 46, 2, 64.88420104980469, 1.7351200580596924, 0.20410999655723572)\n",
      " (15, 1, 1, 56.41749954223633, 0.5019199848175049, 0.030729999765753746)\n",
      " (15, 12, 2, -26.90169906616211, 2.5815300941467285, 0.32763001322746277)\n",
      " (15, 13, 2, -5.649501800537109, 0.36044999957084656, 0.053929999470710754)\n",
      " (16, 16, 2, 56.83219909667969, 1.0, 0.4312700033187866)\n",
      " (16, 22, 2, 26.677501678466797, 0.8963900208473206, 0.13186000287532806)\n",
      " (16, 30, 2, -75.39820098876953, 0.6321300268173218, 0.07415000349283218)\n",
      " (16, 32, 2, 57.012699127197266, 1.0, 0.43167001008987427)\n",
      " (16, 43, 2, 79.0250015258789, 0.2817400097846985, 0.05237000063061714)\n",
      " (17, 37, 2, 56.50230026245117, 0.23646000027656555, 0.03198999911546707)\n",
      " (17, 38, 2, 52.18550109863281, 0.8709800243377686, 0.12512999773025513)]\n"
     ]
    }
   ],
   "source": [
    "# Set up formatting for pulling out data (copy from Matthew)\n",
    "ccedType = np.dtype([('event', np.int32), ('detector', np.int8), ('particle_type', np.int8), ('time', np.float64), ('integral', np.float32), ('height', np.float32)])\n",
    "\n",
    "# Try reading in the entire file at once\n",
    "# In this case, I don't need to open the file using open() \n",
    "data = np.genfromtxt(\"../datar/1/cced1\",dtype=ccedType)\n",
    "print(data[0:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, in this case, I don't even have to open the `cced` file before reading it. I can just specify the filename here. So that simplifies things. \n",
    "\n",
    "I don't need this now, but I'm wondering whether it is possible to read in certain parts of the data, or can I only ever read the entire thing from start to finish? I should be able to use the option `skip_header` and `skip_footer`, the number of lines to skip at the beginning and end of the file. The command for this is:\n",
    "\n",
    "    data = np.genfromtxt(\"cced1_part\",dtype=ccedType, skip_header=3, skip_footer=3)\n",
    "    \n",
    "I won't run it here because I don't want to overwrite the `data` matrix I already read in.\n",
    "\n",
    "This looks like a promising route, and better than the `for line in ccedFile` iterator technique. Go with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Parse the data for event information\n",
    "\n",
    "Now that I have the `data` matrix, pull out event information. The `ccedType` specifies what all of the columns look like. As a reminder, the column names are:\n",
    "\n",
    "* `event`\n",
    "* `detector`\n",
    "* `particle_type`\n",
    "* `time`\n",
    "* `integral`\n",
    "* `height`\n",
    "\n",
    "## Event indexing / how to access specific data\n",
    "Play around with the indexing for a while to understand how to access certain information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event 1\n",
      "detector 7\n",
      "particle_type 2\n",
      "time 60.4305000305\n",
      "integral 1.65172\n",
      "height 0.20165\n",
      "(1, 7, 2, 60.43050003051758, 1.6517200469970703, 0.2016499936580658)\n"
     ]
    }
   ],
   "source": [
    "# Print all values for the first interaction\n",
    "print('event',        data[0]['event'])\n",
    "print('detector',     data[0]['detector'])\n",
    "print('particle_type',data[0]['particle_type'])\n",
    "print('time',         data[0]['time'])\n",
    "print('integral',     data[0]['integral'])\n",
    "print('height',       data[0]['height'])\n",
    "print(                data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 7, 2, 60.43050003051758, 1.6517200469970703, 0.2016499936580658)\n",
      " (1, 40, 1, -237.56460189819336, 0.3626599907875061, 0.036979999393224716)\n",
      " (2, 0, 2, 56.02870178222656, 1.0, 0.3765699863433838)\n",
      " (2, 32, 2, 55.8672981262207, 1.0, 0.3800300061702728)\n",
      " (2, 33, 2, 76.49300003051758, 0.17478999495506287, 0.036979999393224716)]\n"
     ]
    }
   ],
   "source": [
    "# Print all values for the first five interactions\n",
    "print(data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "# Print event numbers for event numbers less than 3\n",
    "indices = np.argwhere(data[:]['event']<3)\n",
    "print(indices)\n",
    "print(data[indices]['event'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through `data` and identify when the event number advances\n",
    "\n",
    "I need to go through the events and find bicorrelation events. In that case there would be at least two detector interactions, and their corresponding fission chamber channels, in a single event. First set up a way to look at all interactions within a history.\n",
    "\n",
    "Use an iteractor to go through one by one. According to stackoverflow, it is the most efficient way to go line by line through a giant matrix. Unlike with the read-in method `for line in cleanFile`, all of the data is still stored in `data` so the iterator just goes through the events and prompts when to look at `data`.\n",
    "\n",
    "First set up the framework for iterating through the `data` matrix. Use the python function `enumerate` to loop through the event numbers. If I set it up using the following syntax, python will keep track of the line number `l` and event number `e` together at once:\n",
    "\n",
    "`for l, e in enumerate(data[:]['event']):`\n",
    "\n",
    "For now just run through the first 20 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading line:  0 ; event:  1\n",
      "Reading line:  1 ; event:  1\n",
      "Reading line:  2 ; event:  2\n",
      "The line after event  1 is  2\n",
      "New event number is e= 2\n",
      "Reading line:  3 ; event:  2\n",
      "Reading line:  4 ; event:  2\n",
      "Reading line:  5 ; event:  3\n",
      "The line after event  2 is  5\n",
      "New event number is e= 3\n",
      "Reading line:  6 ; event:  3\n",
      "Reading line:  7 ; event:  4\n",
      "The line after event  3 is  7\n",
      "New event number is e= 4\n",
      "Reading line:  8 ; event:  4\n",
      "Reading line:  9 ; event:  5\n",
      "The line after event  4 is  9\n",
      "New event number is e= 5\n",
      "Reading line:  10 ; event:  5\n",
      "Reading line:  11 ; event:  6\n",
      "The line after event  5 is  11\n",
      "New event number is e= 6\n",
      "Reading line:  12 ; event:  6\n",
      "Reading line:  13 ; event:  7\n",
      "The line after event  6 is  13\n",
      "New event number is e= 7\n",
      "Reading line:  14 ; event:  7\n",
      "Reading line:  15 ; event:  8\n",
      "The line after event  7 is  15\n",
      "New event number is e= 8\n",
      "Reading line:  16 ; event:  8\n",
      "Reading line:  17 ; event:  8\n",
      "Reading line:  18 ; event:  9\n",
      "The line after event  8 is  18\n",
      "New event number is e= 9\n",
      "Reading line:  19 ; event:  9\n"
     ]
    }
   ],
   "source": [
    "# l is the line number of the current line, starting at 0.\n",
    "# e is the event number of the current line, starting at 1\n",
    "\n",
    "# eventNum is the current event number, extending from lines i to j.\n",
    "eventNum = data[0]['event']; # Start with the first event in the data chunk.\n",
    "                             # If reading entire file, this is 1. \n",
    "                             # If reading a chunk, this may be higher.\n",
    "i = 0;                       # First line number of first event is always 0\n",
    "\n",
    "# This is a clever way of keeping track what line you're on. Enumerate through the event numbers, `e`, and python also keeps track of the line number `l`.\n",
    "for l, e in enumerate(data[:20]['event']):\n",
    "    print(\"Reading line: \",l,\"; event: \",e)\n",
    "    \n",
    "    if e == eventNum: # Still on the same event\n",
    "        pass          # Don't do anything.... but hold this here in case I want to add something\n",
    "    \n",
    "    if e != eventNum: # Store info from currentEvent, move onto next event.\n",
    "        j = l         # The last index of eventNum is the previous line\n",
    "        print(\"The line after event \", eventNum, \"is \", j)      # Event number advances\n",
    "        print(\"New event number is e=\", e)\n",
    "        \n",
    "        # This is where all of the event information will be pulled out.\n",
    "        \n",
    "        eventNum = e  # Move on to next event\n",
    "        i = l         # Current line is the first line for next event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of this analysis is not going to look as beautiful because I am essentially going to copy that last chunk of code and build in new capabilities over and over again. So be ready for a lot of repetition and print statements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Store information about detector pair correlations\n",
    "\n",
    "## Set up detector channel information\n",
    "\n",
    "Our detector system has 48 channels, three of which are fission chamber channels (0, 16, and 32). Set up lists of the correct detector channel numbers.\n",
    "\n",
    "Use the function `bicorr.build_ch_lists()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function build_ch_lists in module bicorr:\n",
      "\n",
      "build_ch_lists(print_flag=False)\n",
      "    Generate and return lists of the channel numbers that correspond to the fission chamber and detector channels. This is built for the Chi-Nu array measurements. If the detector array changes, we need to modify this function.\n",
      "    \n",
      "    Note: In the Chi-Nu array, the fission chamber channels correspond to detector channels as follows:\n",
      "      - fc 0 det 1-15\n",
      "      - fc 16 det 17-31\n",
      "      - fc 32 det 33-47\n",
      "      \n",
      "    Run with: chList, fcList, detList, num_dets, num_det_pairs = bicorr.build_ch_lists()\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    print_flag : bool, optional\n",
      "        Print the values of all vectors?\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    chList : ndarray\n",
      "        All channels measurements\n",
      "    fcList : ndarray\n",
      "        Fission chamber channels\n",
      "    detList : ndarray\n",
      "        Detector channels\n",
      "    num_dets : int\n",
      "        Number of detector channels\n",
      "    num_det_pairs : int\n",
      "        Number of pairs of detectors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bicorr.build_ch_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fission chamber channels: [ 0 16 32]\n",
      "Detector channels: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "Number of detectors: 45\n",
      "Number of detector pairs: 990\n"
     ]
    }
   ],
   "source": [
    "chList, fcList, detList, num_dets, num_det_pairs = bicorr.build_ch_lists(print_flag = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify whether the current event is a bicorrelation event\n",
    "\n",
    "Each of the following target tasks will be indicated in the code below by including (TARGET #) in the comments.\n",
    "\n",
    "* First look to see if there are at least three interactions based on the initial and final line numbers for the current event, `i` and `j`. (TARGET 1)\n",
    "* Look to see whether two detector channels had interactions (TARGET 2)\n",
    "* Look to see whether the corresponding fission chamber channels had interactions (TARGET 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l is the line number of the current line, starting at 0.\n",
    "# e is the event number of the current line, starting at 1\n",
    "\n",
    "# eventNum is the current event number, extending from lines i to j.\n",
    "eventNum = data[0]['event']; # Start with the first event in the data chunk.\n",
    "                             # If reading entire file, this is 1. \n",
    "                             # If reading a chunk, this may be higher.\n",
    "i = 0;                       # First line number of first event is always 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to make use of some boolean logic here. If `chs_bool` is a boolean array, then taking the `sum` of `chs_bool` will count the number of `True` instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccedEvent:\n",
      "[(2, 0, 2, 56.02870178222656, 1.0, 0.3765699863433838)\n",
      " (2, 32, 2, 55.8672981262207, 1.0, 0.3800300061702728)\n",
      " (2, 33, 2, 76.49300003051758, 0.17478999495506287, 0.036979999393224716)]\n",
      "chs_present [ 0 32 33]\n",
      "chs_bool [False False  True]\n",
      "ccedEvent:\n",
      "[(8, 17, 2, 56.868499755859375, 0.08842000365257263, 0.038120001554489136)\n",
      " (8, 27, 2, 55.96139907836914, 1.6303999423980713, 0.19290000200271606)\n",
      " (8, 30, 2, 106.2854995727539, 3.3228399753570557, 0.4171999990940094)]\n",
      "chs_present [17 27 30]\n",
      "chs_bool [ True  True  True]\n",
      "[17 27 30]\n",
      "fc_corr [16 16 16]\n",
      "fc_bool [False False False]\n",
      "ccedEvent:\n",
      "[(15, 1, 1, 56.41749954223633, 0.5019199848175049, 0.030729999765753746)\n",
      " (15, 12, 2, -26.90169906616211, 2.5815300941467285, 0.32763001322746277)\n",
      " (15, 13, 2, -5.649501800537109, 0.36044999957084656, 0.053929999470710754)]\n",
      "chs_present [ 1 12 13]\n",
      "chs_bool [ True  True  True]\n",
      "[ 1 12 13]\n",
      "fc_corr [0 0 0]\n",
      "fc_bool [False False False]\n",
      "ccedEvent:\n",
      "[(16, 16, 2, 56.83219909667969, 1.0, 0.4312700033187866)\n",
      " (16, 22, 2, 26.677501678466797, 0.8963900208473206, 0.13186000287532806)\n",
      " (16, 30, 2, -75.39820098876953, 0.6321300268173218, 0.07415000349283218)\n",
      " (16, 32, 2, 57.012699127197266, 1.0, 0.43167001008987427)\n",
      " (16, 43, 2, 79.0250015258789, 0.2817400097846985, 0.05237000063061714)]\n",
      "chs_present [16 22 30 32 43]\n",
      "chs_bool [False  True  True False  True]\n",
      "[22 30 43]\n",
      "fc_corr [16 16 32]\n",
      "fc_bool [ True  True  True]\n",
      "bicorrelation event!\n",
      "[22 30 43]\n",
      "[16 16 32]\n"
     ]
    }
   ],
   "source": [
    "# This is a clever way of keeping track of what line you're on. Enumerate through the event numbers, `e`, and python also keeps track of the line number `l`.\n",
    "for l, e in enumerate(data[:40]['event']):    \n",
    "    if e == eventNum: # Still on the same event\n",
    "        pass          # Hold for later\n",
    "    \n",
    "    if e != eventNum: # Store info from current event, move onto next event.\n",
    "        j = l       # The last index of eventNum is the previous line\n",
    "        n_ints = j-i # Number interactions in current event\n",
    "        \n",
    "        if n_ints > 2: # If there are more than 2 interactions in the event (TARGET 1)\n",
    "            ccedEvent = data[i:j][:] # Pull out the data from this event\n",
    "            print(\"ccedEvent:\")\n",
    "            print(ccedEvent)\n",
    "            \n",
    "            chs_present = ccedEvent[:]['detector'] # What channels triggered?\n",
    "            print(\"chs_present\",chs_present)\n",
    "            \n",
    "            chs_bool = np.in1d(chs_present,detList) # True = detector, False = fission chamber\n",
    "            print(\"chs_bool\",chs_bool)\n",
    "            \n",
    "            if sum(chs_bool)>1: # If at least two interactions were detectors / two or more Trues (TARGET 2)\n",
    "                # Did the corresponding fc's trigger?\n",
    "                dets_present = chs_present[chs_bool] # Which det channels triggered?\n",
    "                print(dets_present)\n",
    "            \n",
    "                fc_corr = (16*np.floor(dets_present/16)).astype(int) # Corresponding fission chambers for each det channel\n",
    "                print(\"fc_corr\",fc_corr)\n",
    "\n",
    "                fc_bool = np.in1d(fc_corr,chs_present) # Did the corresponding fission chamber trigger? (TARGET 3)\n",
    "                print(\"fc_bool\",fc_bool)\n",
    "                \n",
    "                if sum(fc_bool)>1: # If at least two detectors had corresponding fc triggers\n",
    "                    # Only keep events where det and corresponding fc triggered\n",
    "                    print(\"bicorrelation event!\")\n",
    "                    print(dets_present[fc_bool])\n",
    "                    print(fc_corr[fc_bool])\n",
    "\n",
    "        eventNum = e  # Move on to next event\n",
    "        i = l         # Current line is the first line for next event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event 16 is identified as a bicorrelation event. Now that it has been identified, extract relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Identify indices of the verified detector and corresponding fission chamber channels\n",
    "\n",
    "So far, I have identified events that qualify as a bicorr event. Now I need to extract information from that event. I will start by extracting the channel numbers for the detectors that triggered. \n",
    "\n",
    "Test out how to identify indices of elements in one array within another array. This could eventually be a subroutine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d =  0\n",
      "det_ch =  9\n",
      "indices in chs_presnt =  [1]\n",
      "det_indices =  [1 0]\n",
      "fc_indices =  [0 0]\n",
      "d =  1\n",
      "det_ch =  46\n",
      "indices in chs_presnt =  [3]\n",
      "det_indices =  [1 3]\n",
      "fc_indices =  [0 2]\n"
     ]
    }
   ],
   "source": [
    "# Generate a simple 'dummy' list to practice with\n",
    "dets_present = np.array([9,46])\n",
    "chs_present = np.array([0,9,32,46])\n",
    "chs_bool    = np.array([False,True,False,True])\n",
    "fc_corr = np.array([0,32])\n",
    "fc_bool = np.array([True,True])\n",
    "\n",
    "det_indices = np.zeros(len(dets_present),dtype=np.int8) # What channels in chs_present correspond to these det chs\n",
    "fc_indices  = np.zeros(len(fc_corr),dtype=np.int8) # What channels in chs_present are the corresponding fc are these det chs\n",
    "\n",
    "# Loop through all detectors present- determine the corresponding index in chs_present\n",
    "# d is a counter 0, 1, 2...\n",
    "for d in range(0,len(dets_present),1):\n",
    "    print('d = ', d)\n",
    "    print('det_ch = ', dets_present[d])\n",
    "    print('indices in chs_presnt = ', np.where(chs_present == dets_present[d])[0])\n",
    "    det_indices[d] = np.where(chs_present == dets_present[d])[0]\n",
    "    print('det_indices = ', det_indices)\n",
    "    \n",
    "    fc_indices[d]  = np.where(chs_present == fc_corr[d])[0]\n",
    "    print('fc_indices = ', fc_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporate this into the previous chunk of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccedEvent:\n",
      "[(2, 0, 2, 56.02870178222656, 1.0, 0.3765699863433838)\n",
      " (2, 32, 2, 55.8672981262207, 1.0, 0.3800300061702728)\n",
      " (2, 33, 2, 76.49300003051758, 0.17478999495506287, 0.036979999393224716)]\n",
      "chs_present [ 0 32 33]\n",
      "chs_bool [False False  True]\n",
      "ccedEvent:\n",
      "[(8, 17, 2, 56.868499755859375, 0.08842000365257263, 0.038120001554489136)\n",
      " (8, 27, 2, 55.96139907836914, 1.6303999423980713, 0.19290000200271606)\n",
      " (8, 30, 2, 106.2854995727539, 3.3228399753570557, 0.4171999990940094)]\n",
      "chs_present [17 27 30]\n",
      "chs_bool [ True  True  True]\n",
      "[17 27 30]\n",
      "fc_corr [16 16 16]\n",
      "fc_bool [False False False]\n",
      "ccedEvent:\n",
      "[(15, 1, 1, 56.41749954223633, 0.5019199848175049, 0.030729999765753746)\n",
      " (15, 12, 2, -26.90169906616211, 2.5815300941467285, 0.32763001322746277)\n",
      " (15, 13, 2, -5.649501800537109, 0.36044999957084656, 0.053929999470710754)]\n",
      "chs_present [ 1 12 13]\n",
      "chs_bool [ True  True  True]\n",
      "[ 1 12 13]\n",
      "fc_corr [0 0 0]\n",
      "fc_bool [False False False]\n",
      "ccedEvent:\n",
      "[(16, 16, 2, 56.83219909667969, 1.0, 0.4312700033187866)\n",
      " (16, 22, 2, 26.677501678466797, 0.8963900208473206, 0.13186000287532806)\n",
      " (16, 30, 2, -75.39820098876953, 0.6321300268173218, 0.07415000349283218)\n",
      " (16, 32, 2, 57.012699127197266, 1.0, 0.43167001008987427)\n",
      " (16, 43, 2, 79.0250015258789, 0.2817400097846985, 0.05237000063061714)]\n",
      "chs_present [16 22 30 32 43]\n",
      "chs_bool [False  True  True False  True]\n",
      "[22 30 43]\n",
      "fc_corr [16 16 32]\n",
      "fc_bool [ True  True  True]\n",
      "bicorrelation event!\n",
      "dets_present: [22 30 43]\n",
      "fc_corr: [16 16 32]\n",
      "det_indices =  [0 0 0]\n",
      "d =  0\n",
      "det_ch =  22\n",
      "index in chs_present =  [1]\n",
      "det_indices =  [1 0 0]\n",
      "fc_indices =  [0 0 0]\n",
      "d =  1\n",
      "det_ch =  30\n",
      "index in chs_present =  [2]\n",
      "det_indices =  [1 2 0]\n",
      "fc_indices =  [0 0 0]\n",
      "d =  2\n",
      "det_ch =  43\n",
      "index in chs_present =  [4]\n",
      "det_indices =  [1 2 4]\n",
      "fc_indices =  [0 0 3]\n"
     ]
    }
   ],
   "source": [
    "for l, e in enumerate(data[:40]['event']):\n",
    "    # print(\"Reading line: \",l,\"; event: \",e)\n",
    "    \n",
    "    if e == eventNum: # Still on the same event\n",
    "        pass          # Don't do anything.... but hold this here in case I want to add something\n",
    "    \n",
    "    if e != eventNum: # Store info from current event, move onto next event.\n",
    "        j = l       # The last index of eventNum is the previous line\n",
    "        n_ints = j-i # Number interactions in current event\n",
    "        \n",
    "        if n_ints > 2: # If there are more than 2 interactions in the event\n",
    "            ccedEvent = data[i:j][:] # Pull out the data from this event\n",
    "            print(\"ccedEvent:\")\n",
    "            print(ccedEvent)\n",
    "            chs_present = ccedEvent[:]['detector'] # What channels triggered?\n",
    "            print(\"chs_present\",chs_present)\n",
    "            \n",
    "            chs_bool = np.in1d(chs_present,detList) # True = detector, False = fission chamber\n",
    "            print(\"chs_bool\",chs_bool)\n",
    "            \n",
    "            if sum(chs_bool)>1: # If at least two interactions were detectors / two or more Trues\n",
    "                # Did the corresponding fc's trigger?\n",
    "                dets_present = chs_present[chs_bool] # Which det channels triggered?\n",
    "                print(dets_present)\n",
    "            \n",
    "                fc_corr = 16*np.floor(dets_present/16) # Corresponding fission chambers for each det channel\n",
    "                fc_corr = fc_corr.astype(int) # Convert to int\n",
    "                print(\"fc_corr\",fc_corr)\n",
    "\n",
    "                fc_bool = np.in1d(fc_corr,chs_present) # Did the corresponding fission chamber trigger?\n",
    "                print(\"fc_bool\",fc_bool)\n",
    "                \n",
    "                if sum(fc_bool)>1: # If at least two detectors had corresponding fc triggers\n",
    "                    # Only keep events where det and corresponding fc triggered (fc_bool = True)\n",
    "                    print(\"bicorrelation event!\")\n",
    "                    dets_present = dets_present[fc_bool]\n",
    "                    print('dets_present:',dets_present)\n",
    "                    fc_corr      = fc_corr[fc_bool]\n",
    "                    print('fc_corr:',fc_corr)\n",
    "                    # Log dead events? Look for interactions where this happens\n",
    "                    \n",
    "                    \n",
    "                    det_indices = np.zeros(len(dets_present),dtype=np.int8) # What channels in chs_present correspond to these det chs\n",
    "                    fc_indices  = np.zeros(len(fc_corr),dtype=np.int8) # What channels in chs_present are the corresponding fc are these det chs\n",
    "                    print('det_indices = ',det_indices)\n",
    "                    for d in range(0,len(dets_present),1): #(TARGET)\n",
    "                        print('d = ', d)\n",
    "                        print('det_ch = ', dets_present[d])\n",
    "                        print('index in chs_present = ', np.where(chs_present == dets_present[d])[0])\n",
    "                        det_indices[d] = np.where(chs_present == dets_present[d])[0]\n",
    "                        print('det_indices = ', det_indices)\n",
    "\n",
    "                        fc_indices[d]  = np.where(chs_present == fc_corr[d])[0]\n",
    "                        print('fc_indices = ', fc_indices)\n",
    "                        \n",
    "        eventNum = e  # Move on to next event\n",
    "        i = l         # Current line is the first line for next event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Store timing info, detector pair, correlation type\n",
    "\n",
    "## Pull out timing information and particle type from all pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct for time offset\n",
    "\n",
    "There are a few detector effects that make it so that there is a constant time offset between each detector pair. Matthew has calculated these time offsets (although they are not all accurate) so I need to implement a correction.\n",
    "\n",
    "Follow the technique he uses in his `crossCorr_v4.py` script. First explore what the `timeOffsetData.txt` looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../datar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " 'bicorr1',\n",
       " 'cced1',\n",
       " 'cced1_note.md',\n",
       " 'cced1_part',\n",
       " 'cced1_part_note.md']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cced1', 'timeOffset.txt']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(root_path + '/' + str(folder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 1\n",
    "timeOffsetData = np.genfromtxt(os.path.join(root_path + '/' + str(folder) + '/timeOffset.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAAGHCAYAAAAqZvLgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncv4/czZRiTdnM48AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(chList,chList[:-1],timeOffsetData)\n",
    "plt.xlabel('Detector 1')\n",
    "plt.ylabel('Detector 2')\n",
    "plt.title('Time offset between detector pairs (ns)')\n",
    "plt.xlim([0,47])\n",
    "plt.ylim([0,46])\n",
    "plt.colorbar()\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for calling a value from `timeOffsetData` is:\n",
    "\n",
    "    timeOffsetData[d1][d2]\n",
    "    \n",
    "where `d1` is the first detector channel number and `d2` is the second detector channel number. In all cases, `d1` must be less than `d2`. The indices where `d1` is greater than `d2` are empty in `timeDataOffset`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to look at Matthew's `crossCorr_v4.py` script and see how he implements `timeOffsetData`. The lines where he implements it are lines 147-152:\n",
    "\n",
    "            if jDetIndex < iDetIndex: \n",
    "                timeOffset = -float(timeOffsetList[int(ccEvent['detector'][j])][int(ccEvent['detector'][i])])\n",
    "            else:\n",
    "                timeOffset = -float(timeOffsetList[int(ccEvent['detector'][i])][int(ccEvent['detector'][j])])\n",
    "            \n",
    "            dT = float(ccEvent['time'][i]) - float(ccEvent['time'][j]) + timeOffset\n",
    "            \n",
    "I would like to make my implementation simpler. Matthew calculates a negative time offset, then adds that. But what makes it the most difficult to read is the indexing... rather than just a `d1` or `d2` number, Matthew uses `int(ccEvent['detector'][j])` which is very lengthy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look back at how I calculate `dt`. Is it possible to call the time offset values for all detectors at once?\n",
    "\n",
    "I have the detector channels that triggered in a vector, and their corresponding fission chamber channels. Can I call them together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22 30 43]\n",
      "[16 16 32]\n",
      "-8.6141215\n",
      "30.010797\n"
     ]
    }
   ],
   "source": [
    "print(dets_present)\n",
    "print(fc_corr)\n",
    "\n",
    "print(timeOffsetData[0][15])\n",
    "print(timeOffsetData[fc_corr[0]][dets_present[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like I can't call two indices at once by just calling `timeOffsetData[fc_corr][dets_present]`. Instead I need to create a new array of time offset values for the detectors involved in the interaction. Build it into the code I developed above `(indicated by #(TARGET)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicorrelation!\n",
      "[(16, 16, 2, 56.83219909667969, 1.0, 0.4312700033187866)\n",
      " (16, 22, 2, 26.677501678466797, 0.8963900208473206, 0.13186000287532806)\n",
      " (16, 30, 2, -75.39820098876953, 0.6321300268173218, 0.07415000349283218)\n",
      " (16, 32, 2, 57.012699127197266, 1.0, 0.43167001008987427)\n",
      " (16, 43, 2, 79.0250015258789, 0.2817400097846985, 0.05237000063061714)]\n",
      "det_indices [1 2 4]\n",
      "fc_indices [0 0 3]\n",
      "dt [  -0.14390042 -143.50948809   11.6941294 ]\n",
      "par_type [2 2 2]\n",
      "bicorrelation!\n",
      "[(44, 16, 2, 56.16529846191406, 1.0, 0.4361000061035156)\n",
      " (44, 29, 1, 111.27939987182617, 2.1337499618530273, 0.23030999302864075)\n",
      " (44, 32, 2, 56.51639938354492, 1.0, 0.4403199851512909)\n",
      " (44, 37, 1, 113.06719970703125, 1.0750700235366821, 0.10875999927520752)]\n",
      "det_indices [1 3]\n",
      "fc_indices [0 2]\n",
      "dt [ 40.87007441  46.09551632]\n",
      "par_type [1 1]\n"
     ]
    }
   ],
   "source": [
    "for l, e in enumerate(data[:100]['event']):\n",
    "    # print(\"Reading line: \",l,\"; event: \",e)\n",
    "    \n",
    "    if e == eventNum: # Still on the same event\n",
    "        pass          # Don't do anything.... but hold this here in case I want to add something\n",
    "    \n",
    "    if e != eventNum: # Store info from current event, move onto next event.\n",
    "        j = l       # The last index of eventNum is the previous line\n",
    "        n_ints = j-i # Number interactions in current event\n",
    "        \n",
    "        if n_ints > 2: # If there are more than 2 interactions in the event\n",
    "            ccedEvent = data[i:j][:] # Pull out the data from this event\n",
    "            chs_present = ccedEvent[:]['detector'] # What channels triggered?            \n",
    "            chs_bool = np.in1d(chs_present,detList) # True = detector, False = fission chamber\n",
    "            \n",
    "            if sum(chs_bool)>1: # If at least two interactions were detectors / two or more Trues\n",
    "                # Did the corresponding fc's trigger?\n",
    "                dets_present = chs_present[chs_bool] # Which det channels triggered?\n",
    "            \n",
    "                fc_corr = 16*np.floor(dets_present/16) # Corresponding fission chambers for each det channel\n",
    "                fc_corr = fc_corr.astype(int) # Convert to int\n",
    "                fc_bool = np.in1d(fc_corr,chs_present) # Did the corresponding fission chamber trigger?\n",
    "                \n",
    "                if sum(fc_bool)>1: # If at least two detectors had corresponding fc triggers\n",
    "                    print('bicorrelation!')\n",
    "                    print(ccedEvent)\n",
    "                    \n",
    "                    # Only keep events where det and corresponding fc triggered (fc_bool = True)\n",
    "                    dets_present = dets_present[fc_bool]\n",
    "                    fc_corr      = fc_corr[fc_bool]                    \n",
    "                    \n",
    "                    det_indices = np.zeros(len(dets_present),dtype=np.int8) # What channels in chs_present correspond to these det chs\n",
    "                    fc_indices  = np.zeros(len(fc_corr),dtype=np.int8) # What channels in chs_present are the corresponding fc are these det chs\n",
    "                    time_offset = np.zeros(len(dets_present),dtype=np.float64) #(TARGET)\n",
    "                    for d in range(0,len(dets_present),1):\n",
    "                        det_indices[d] = np.where(chs_present == dets_present[d])[0]\n",
    "                        fc_indices[d]  = np.where(chs_present == fc_corr[d])[0]\n",
    "                        time_offset[d] = timeOffsetData[fc_corr[d]][dets_present[d]]  #(TARGET)\n",
    "                        \n",
    "                    print('det_indices',det_indices)\n",
    "                    print('fc_indices',fc_indices)\n",
    "                    \n",
    "                    # Store dt and particle type for each detector event\n",
    "                    dt       = np.zeros(len(dets_present),dtype=np.int8)\n",
    "                    par_type = np.zeros(len(dets_present),dtype=np.int8)\n",
    "                    \n",
    "                    # Correct for time offset\n",
    "                    dt       = ccedEvent[det_indices]['time']-ccedEvent[fc_indices]['time']+time_offset\n",
    "                    print('dt',dt)\n",
    "                    par_type = ccedEvent[det_indices]['particle_type']\n",
    "                    print('par_type',par_type)  # par_type 1=n, 2=p\n",
    "        \n",
    "        eventNum = e  # Move on to next event\n",
    "        i = l         # Current line is the first line for next event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the time offset worked. Look at event 16.\n",
    "\n",
    "Without time offset correction:\n",
    "```\n",
    "ccedEvent:\n",
    "[(16, 16, 2, 56.83219909667969, 1.0, 0.4312700033187866)\n",
    " (16, 22, 2, 26.677501678466797, 0.8963900208473206, 0.13186000287532806)\n",
    " (16, 30, 2, -75.39820098876953, 0.6321300268173218, 0.07415000349283218)\n",
    " (16, 32, 2, 57.012699127197266, 1.0, 0.43167001008987427)\n",
    " (16, 43, 2, 79.0250015258789, 0.2817400097846985, 0.05237000063061714)]\n",
    "chs_present: [16 22 30 32 43]\n",
    "dets_present: [22 30 43]\n",
    "fc_corr: [16 16 32]\n",
    "det_indices [1 2 4]\n",
    "fc_indices [0 0 3]\n",
    "dt [ -30.15469742 -132.23040009   22.0123024 ]\n",
    "par_type [2 2 2]\n",
    "```\n",
    "\n",
    "With time offset correction:\n",
    "```\n",
    "ccedEvent:\n",
    "[(16, 16, 2, 56.83219909667969, 1.0, 0.4312700033187866)\n",
    " (16, 22, 2, 26.677501678466797, 0.8963900208473206, 0.13186000287532806)\n",
    " (16, 30, 2, -75.39820098876953, 0.6321300268173218, 0.07415000349283218)\n",
    " (16, 32, 2, 57.012699127197266, 1.0, 0.43167001008987427)\n",
    " (16, 43, 2, 79.0250015258789, 0.2817400097846985, 0.05237000063061714)]\n",
    "chs_present: [16 22 30 32 43]\n",
    "dets_present: [22 30 43]\n",
    "fc_corr: [16 16 32]\n",
    "det_indices [1 2 4]\n",
    "fc_indices [0 0 3]\n",
    "dt [ -60.16549442 -120.95131209   32.3304754 ]\n",
    "par_type [2 2 2]\n",
    "```\n",
    "\n",
    "The first detector is channel 22. What is the time offset between that channel and the corresponding fission chamber on channel 16?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.010797\n"
     ]
    }
   ],
   "source": [
    "print(timeOffsetData[16][22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in `dt` with and without the time offset correction is adjusted by that amount, so call it correct. The question remains, should I be adding or subtracting the time offset? At first I was subtracting the `time_offset`, but the $\\gamma\\gamma$ distribution was not centered at (0,0), so I changed it to adding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Write out each bicorrelation event to a text file called `bicorr`. \n",
    "\n",
    "Practice writing out variables to a text file. What information do I want to store from the bicorrelation event?\n",
    "\n",
    "* col 1) Event number\n",
    "* col 2) Det 1 CH\n",
    "* col 3) Det 1 particle type\n",
    "* col 4) Det 1 $\\Delta t_1$\n",
    "* col 5) Det 2 CH\n",
    "* col 6) Det 2 particle type\n",
    "* col 7) Det 2 $\\Delta t_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4360\n",
      "[ -78.15717977 -125.34806059]\n",
      "[15 40]\n",
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "# Open a text file to write to\n",
    "printFile = open('../datar/1/bicorr1','w')\n",
    "\n",
    "print(ccedEvent[0]['event'])\n",
    "print(dt)\n",
    "print(dets_present)\n",
    "print(par_type)\n",
    "\n",
    "d1 = 0\n",
    "d2 = 1\n",
    "printFile.write(str(ccedEvent[0]['event']) + '  ' + str(dets_present[d1]) + '  ' + str(par_type[d1]) + '  ' + str(dt[d1]) \n",
    "                                           + '  ' + str(dets_present[d2]) + '  ' + str(par_type[d2]) + '  ' + str(dt[d2]))\n",
    "printFile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the contents of the file I just generated here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4360  15  1  -78.1571797695  40  2  -125.34806059\n"
     ]
    }
   ],
   "source": [
    "with open('../datar/1/bicorr1') as f: # The with keyword automatically closes the file when you are done\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now insert this into the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fission chamber channels: [ 0 16 32]\n",
      "Detector channels: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "Number of detectors: 45\n",
      "Number of detector pairs: 990\n"
     ]
    }
   ],
   "source": [
    "# Open a text file to write to\n",
    "printFile = open('../datar/1/bicorr1','w')\n",
    "\n",
    "# Identify whether each event was a bicorrelation event by looking at the number of interactions and the channel numbers\n",
    "chList, fcList, detList, num_dets, num_det_pairs = bicorr.build_ch_lists(print_flag = True)\n",
    "\n",
    "# l is the line number of the current line, starting at 0.\n",
    "# e is the event number of the current line, starting at 1\n",
    "\n",
    "# eventNum is the current event number. From lines i to j.\n",
    "eventNum = data[0]['event']; # Start with the first event in the data chunk.\n",
    "                             # If reading entire file, this is 1. If reading a chunk, this may be higher\n",
    "i        = 0;                # First line number of first event is always 0\n",
    "\n",
    "for l, e in enumerate(data[:]['event']):\n",
    "    if e == eventNum: # Still on the same event\n",
    "        pass          \n",
    "    \n",
    "    if e != eventNum:                                  # Store info from current event, move onto next event.\n",
    "        j = l                                          # The last index of eventNum is the previous line\n",
    "        n_ints = j-i                                   # Number interactions in current event\n",
    "        \n",
    "        if n_ints > 2:                                 # If > 2 interactions in the event\n",
    "            ccedEvent = data[i:j][:]                   # Pull out the data from this event\n",
    "            chs_present = ccedEvent[:]['detector']     # What channels triggered?\n",
    "            chs_bool = np.in1d(chs_present,detList)    # True = detector, False = fission chamber\n",
    "            \n",
    "            if sum(chs_bool)>1:                        # If >2 detectors, did corr fc's trigger?\n",
    "                dets_present = chs_present[chs_bool]   # Which det channels triggered?\n",
    "                \n",
    "                fc_corr = (16*np.floor(dets_present/16)).astype(int) # Corr fc for each det ch\n",
    "\n",
    "                fc_bool = np.in1d(fc_corr,chs_present) # Did the corresponding fission chamber trigger?\n",
    "                \n",
    "                if sum(fc_bool)>1:                     # If >2 det + corr fc, keep those\n",
    "                    dets_present = dets_present[fc_bool]\n",
    "                    fc_corr      = fc_corr[fc_bool]                    \n",
    "                    \n",
    "                    det_indices = np.zeros(len(dets_present),dtype=np.int8)    # Where does chs_present = these det chs?\n",
    "                    fc_indices  = np.zeros(len(fc_corr),dtype=np.int8)         # Where does chs_present = these fc chs?\n",
    "                    time_offset = np.zeros(len(dets_present),dtype=np.float64) # Store time offset\n",
    "                    \n",
    "                    for d in range(0,len(dets_present),1):\n",
    "                        det_indices[d] = np.where(chs_present == dets_present[d])[0]\n",
    "                        fc_indices[d]  = np.where(chs_present == fc_corr[d])[0]\n",
    "                        time_offset[d] = timeOffsetData[fc_corr[d]][dets_present[d]]\n",
    "                    \n",
    "                    # Store dt and particle type for each detector event\n",
    "                    dt       = np.zeros(len(dets_present),dtype=np.int8)\n",
    "                    par_type = np.zeros(len(dets_present),dtype=np.int8)\n",
    "                    \n",
    "                    # Correct for time offset\n",
    "                    dt       = ccedEvent[det_indices]['time']-ccedEvent[fc_indices]['time']-time_offset\n",
    "                    par_type = ccedEvent[det_indices]['particle_type']\n",
    "                    \n",
    "                    # Write out event info from all detector pairs\n",
    "                    for d1 in range(0,len(det_indices)-1,1):\n",
    "                        for d2 in range(d1+1,len(det_indices),1):\n",
    "                            printFile.write(str(ccedEvent[0]['event'])\n",
    "                                            + '  ' + str(dets_present[d1]) + '  ' + str(par_type[d1]) + '  ' + str(dt[d1]) \n",
    "                                            + '  ' + str(dets_present[d2]) + '  ' + str(par_type[d2]) + '  ' + str(dt[d2])\n",
    "                                            + '\\n')\n",
    "        \n",
    "        eventNum = e  # Move on to next event\n",
    "        i = l         # Current line is the first line for next event\n",
    "        \n",
    "        \n",
    "printFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bicorr` file that was produced has multiple lines for some events:\n",
    "\n",
    "```\n",
    "16  22  2  -30.1546974182  30  2  -132.230400085\n",
    "16  22  2  -30.1546974182  43  2  22.0123023987\n",
    "16  30  2  -132.230400085  43  2  22.0123023987\n",
    "44  29  1  55.1141014099  37  1  56.5508003235\n",
    "52  10  2  206.289699554  30  2  10.6130981445\n",
    "76  10  2  -112.366802216  14  2  -34.8992996216\n",
    "87  4  1  41.3330993652  38  2  7.32550048828\n",
    "93  19  1  13.7381019592  20  2  -27.9251976013\n",
    "98  7  2  -127.604602814  34  2  10.223400116\n",
    "98  7  2  -127.604602814  37  2  -73.8257026672\n",
    "98  34  2  10.223400116  37  2  -73.8257026672\n",
    "99  22  2  187.418201447  26  2  185.284301758\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good. I need to try it on the cluster, and figure out how to run it in all of the subfolders. Functionalize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Read and write into multiple subfolders\n",
    "\n",
    "So far I am just reading one file from folder 1. I need to read multiple `cced` files in different subfolders and write a `bicorr` file into each of those subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "folders = np.arange(1,3,1)\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "../datar//1/cced1\n",
      "2\n",
      "../datar//2/cced2\n"
     ]
    }
   ],
   "source": [
    "cced_root = 'cced'\n",
    "root_path = '../datar/'\n",
    "\n",
    "for folder in folders:\n",
    "    cced_open = os.path.join(root_path + '/' + str(folder)+'/'+cced_root+str(folder))\n",
    "    \n",
    "    print(folder)\n",
    "    print(cced_open)\n",
    "    \n",
    "    data = np.genfromtxt(cced_open,dtype=ccedType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I folded this into the `bicorr.py` script.\n",
    "\n",
    "This produces a `bicorr` file in each folder. I would like to combine them into one giant `bicorr` file. Try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "opening: ../datar//1/bicorr1\n",
      "opening: ../datar//2/bicorr2\n"
     ]
    }
   ],
   "source": [
    "folders = np.arange(1,3,1)#np.array([1,2])\n",
    "print(folders)\n",
    "\n",
    "with open('bicorr_all','w') as outfile:\n",
    "    for folder in folders:\n",
    "        bicorr_file = os.path.join(root_path + '/' + str(folder)+'/'+'bicorr'+str(folder))\n",
    "        print('opening:',bicorr_file)\n",
    "        with open(bicorr_file) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Put it all together\n",
    "\n",
    "I combined all of these steps into a function called `generate_bicorr` in my `bicorr.py` module. View the contents of that function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def generate_bicorr(folder_start=1,folder_end=2,root_path=None):\n",
      "    \"\"\"\n",
      "\tParse cced files and produce bicorr output file in each folder from folder_start up to (not including) folder_end.     Developed in fnpc\\analysis\\2016_11_30_pfs_bicorrelation_plot\\generate_bicorr_from_cced.ipynb\n",
      "\t\t\n",
      "\tReads in cced file, format: event, detector, particle_type, time, integral, height\n",
      "\tProduces bicorr file, format: event, det1ch, det1par, det1t, det2ch, det2par, det2t\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    folder_start : int, optional\n",
      "        First folder\n",
      "    folder_end : int, optional\n",
      "        Last folder + 1 (for example, folder_end = 2 will end at folder 1)\n",
      "    root_path : int, optional\n",
      "        Relative path to folder where data folders exist (1, 2, 3, etc.). default = cwd\n",
      "    \n",
      "    Returns\n",
      "    ------- \n",
      "    n/a\n",
      "\t\"\"\"\n",
      "    # If no data path provided, look for data folders here\n",
      "    if root_path == None: root_path = os.getcwd()\n",
      "    \n",
      "    # Folders to run\n",
      "    folders = np.arange(folder_start,folder_end,1)\n",
      "    print('Generating bicorr file for folders: ', folders)\n",
      "    \n",
      "    # Set up formatting for pulling out data (copy from Matthew)\n",
      "    cced_root = 'cced'\n",
      "    print_root = 'bicorr'\n",
      "    ccedType = np.dtype([('event', np.int32), ('detector', np.int8), ('particle_type', np.int8), ('time', np.float16), ('integral', np.float32), ('height', np.float32)])\n",
      "    \n",
      "    # Detector info\n",
      "    chList, fcList, detList, num_dets, num_det_pairs = build_ch_lists()\n",
      "\n",
      "    # Run through folders\n",
      "    for folder in folders:    \n",
      "        # Open timeOffsetData.txt in that folder\n",
      "        timeOffsetData = np.genfromtxt(os.path.join(root_path + '/' + str(folder)+'/timeOffset.txt'))\n",
      "    \n",
      "        cced_open = os.path.join(root_path + '/' + str(folder)+'/'+cced_root+str(folder))\n",
      "        print('processing:',folder)\n",
      "        print('opening:',cced_open)\n",
      "\n",
      "        # Try reading in the entire file at once\n",
      "        # In this case, I don't need to open the file using open() \n",
      "        data = np.genfromtxt(cced_open,dtype=ccedType)\n",
      "\n",
      "        # Open a text file to write to\n",
      "        print_file = open(os.path.join(root_path + '/' + str(folder)+'/'+print_root+str(folder)),'w')\n",
      "        print('write to:',print_file)\n",
      "\n",
      "        # eventNum is the current event number. From lines i to j.\n",
      "        eventNum = data[0]['event']; # Start with the first event in the data chunk.\n",
      "                                     # If reading entire file, this is 1. If reading a chunk, this may be higher\n",
      "        i        = 0;                # First line number of first event is always 0\n",
      "\n",
      "        # Run through the data matrix (all information from cced file)        \n",
      "        #     l is the line number of the current line, starting at 0.\n",
      "        #     e is the event number of the current line, starting at 1\n",
      "        for l, e in enumerate(data[:]['event']):\n",
      "            \n",
      "            if e == eventNum: # Still on the same event\n",
      "                pass          \n",
      "            \n",
      "            if e != eventNum:                                # Store info from current event, move onto next event.\n",
      "                j = l                                        # The last index of eventNum is the previous line\n",
      "                n_ints = j-i                                 # Number interactions in current event\n",
      "                                                             \n",
      "                if n_ints > 2:                               # If > 2 interactions in current event\n",
      "                    ccedEvent = data[i:j][:]                 # Data from this event\n",
      "                    chs_present = ccedEvent[:]['detector']   # What channels triggered?\t\t\t\t\n",
      "                    chs_bool = np.in1d(chs_present,detList)  # True = detector, False = fission chamber\n",
      "                                                             \n",
      "                    if sum(chs_bool)>1:                      # If >2 dets, did corr fc's trigger?\n",
      "                        dets_present = chs_present[chs_bool] # Which det ch's triggered?\n",
      "                    \n",
      "                        fc_corr = (16*np.floor(dets_present/16)).astype(int) # Corr fc for each det ch\n",
      "                        fc_bool = np.in1d(fc_corr,chs_present)               # Did fc corr trigger?\n",
      "                        \n",
      "                            # Bicorrelation events only!1\n",
      "                        if sum(fc_bool)>1:                   # If >2 det + corr fc, keep those\n",
      "                            dets_present = dets_present[fc_bool]\n",
      "                            fc_corr      = fc_corr[fc_bool]\n",
      "                            \n",
      "                            det_indices = np.zeros(len(dets_present),dtype=np.int8)    # Where does chs_present = these det chs?\n",
      "                            fc_indices  = np.zeros(len(fc_corr),dtype=np.int8)         # Where does chs_present = these fc chs?\n",
      "                            time_offset = np.zeros(len(dets_present),dtype=np.float16) # Store time offset\n",
      "                            for d in range(0,len(dets_present),1):\n",
      "                                det_indices[d] = np.where(chs_present == dets_present[d])[0]\n",
      "                                fc_indices[d]  = np.where(chs_present == fc_corr[d])[0]\n",
      "                                time_offset[d] = timeOffsetData[fc_corr[d]][dets_present[d]]\n",
      "                            \n",
      "                            # Store dt and particle type for each detector event\n",
      "                            dt       = ccedEvent[det_indices]['time']-ccedEvent[fc_indices]['time']+time_offset\n",
      "                            par_type = ccedEvent[det_indices]['particle_type']\n",
      "                            \n",
      "                            # Write out event info from all detector pairs\n",
      "                            for d1 in range(0,len(det_indices)-1,1):\n",
      "                                for d2 in range(d1+1,len(det_indices),1):\n",
      "                                    print_file.write(str(ccedEvent[0]['event'])\n",
      "                                        + '  ' + str(dets_present[d1]) + '  ' + str(par_type[d1]) + '  ' + str(dt[d1]) \n",
      "                                        + '  ' + str(dets_present[d2]) + '  ' + str(par_type[d2]) + '  ' + str(dt[d2])\n",
      "                                        + '\\n')\n",
      "                    \n",
      "                eventNum = e  # Move on to next event\n",
      "                i = l         # Current line is the first line for next event\n",
      "\n",
      "        print_file.close()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(bicorr.generate_bicorr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating bicorr file for folders:  [1 2]\n",
      "processing: 1\n",
      "opening: ../datar/1/cced1\n",
      "write to: <_io.TextIOWrapper name='../datar/1/bicorr1' mode='w' encoding='cp1252'>\n",
      "processing: 2\n",
      "opening: ../datar/2/cced2\n",
      "write to: <_io.TextIOWrapper name='../datar/2/bicorr2' mode='w' encoding='cp1252'>\n"
     ]
    }
   ],
   "source": [
    "bicorr.generate_bicorr(folder_start=1,folder_end=3,root_path='../datar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Update: Add pulse height threshold\n",
    "\n",
    "Matthew pointed out that I need to implement a pulse height threshold in my analysis. I had not included one, and he ran the dat with a very low pulse height threshold (40 keVee). I need to implement one at 100 keVee (a little conservative vs. 80 keVee but we will try it there first).\n",
    "\n",
    "I am going to tack this on to the end of this notebook rather than rewriting the notebook. Let's see.\n",
    "\n",
    "As a reminder, the format of the `cced` file is:\n",
    "\n",
    "* 1) event number: `evnum`\n",
    "* 2) channel number `chnum`\n",
    "* 3) particle (1=n, 2=g) `part`\n",
    "* 4) time, $ns$ `time`\n",
    "* 5) PSD total integral `totint`\n",
    "* 6) pulse height `height`\n",
    "\n",
    "The pulse height column is already calibration to MeVee, so I can set a threshold on that column to 0.1. I need both neutrons to exceed 0.1 MeVee. \n",
    "\n",
    "I'm going to run it first without this energy threshold, and then run it with the energy threshold and see how things compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
